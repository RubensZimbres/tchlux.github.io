---
title: Publications
---

- ORCID: 0000-0002-1858-4724
- [Google Scholar](https://scholar.google.com/citations?user=wamfO3sAAAAJ&hl=en)
- [DBLP](https://dblp.org/pers/hd/l/Lux:Thomas) (imperfect matches)

# First Author Publications

<hr>
#### A Case Study on a Sustainable Framework for Ethically Aware Predictive Modeling
*November, 2019* [[pdf](http://people.cs.vt.edu/tchlux/papers/tchlux-2019-ISTAS.pdf)] [[link](https://attend.ieee.org/istas-2019/wp-content/uploads/sites/133/2019/11/IEEE-ISTAS2019_Program_121119.pdf)]

Many applications of predictive models like criminal activity heatmapping, recidivism estimation, and child safety scoring rely on data that may be incomplete, incorrect, or biased. Many sensitive social and historical issues can unintentionally be incorporated into predictions causing ethical mistreatment. This work proposes a mechanism for continuously mitigating model bias by using algorithms that produce predictions from reasonably small subsets of data, allowing a human-in-the-loop approach to model application. The benefits offered by this framework are twofold: (1) bias can be identified either statistically or by human users on a per-prediction basis; (2) data can be cleaned for bias on a per-prediction basis.

<hr>
#### Least Squares Solutions to Polynomial Systems of Equations with Quantum Annealing
*November, 2019* [[pdf](http://people.cs.vt.edu/tchlux/papers/tchlux-2019-QIP.pdf)] [[link](https://link.springer.com/article/10.1007%2Fs11128-019-2489-x)]

This work proposes and analyzes a methodology for finding least-squares solutions to the systems of polynomial equations. The proposed methodology maps the squared-error function for a polynomial equation onto the Ising–Hamiltonian model, ensuring that the approximate solutions (by least squares) to real-world problems can be computed on a quantum annealer even when the exact solutions do not exist. Hamiltonians for integer factorization and polynomial systems of equations are implemented and analyzed for both logical optimality and physical practicality on modern quantum annealing hardware.

<hr>
#### Nonparametric Distribution Models for Predicting and Managing Computational Performance Variability
*April, 2018* [[pdf](http://people.cs.vt.edu/tchlux/papers/tchlux-2018-IEEESE.pdf)] [[link](https://ieeexplore.ieee.org/document/8478814)]

Performance variability can have a significant impact on many applications of computing. Cloud computing, high performance computing, and computer security communities each exert considerable effort managing and analyzing variability throughout the system stack. This work presents and evaluates a methodology for predicting precise characteristics of the computational performance variability of an input/output (I/O) application over varying system configurations.


<hr>
#### Predictive Modeling of I/O Characteristics in High Performance Computing Systems
*April, 2018* [[pdf](http://people.cs.vt.edu/tchlux/papers/tchlux-2018-HPC_SpringSim.pdf)] [[link](https://dl.acm.org/citation.cfm?id=3213077)]

Each of high performance computing, cloud computing, and computer security have their own interests in modeling and predicting the performance of computers with respect to how they are configured. An effective model might infer internal mechanics, minimize power consumption, or maximize computational throughput of a given system. This paper analyzes a four-dimensional dataset measuring the input/output (I/O) characteristics of a cluster of identical computers using the benchmark IOzone. The I/O performance characteristics are modeled with respect to system configuration using multivariate interpolation and approximation techniques.

<hr>
#### Novel Meshes for Multivariate Interpolation and Approximation
*March, 2018* [[pdf](http://people.cs.vt.edu/tchlux/papers/tchlux-2018-ACMSE.pdf)] [[link](https://dl.acm.org/citation.cfm?id=3190687)]

A rapid increase in the quantity of data available is allowing all fields of science to generate more accurate models of multivariate phenomena. Regression and interpolation become challenging when the dimension of data is large, especially while maintaining tractable computational complexity. This paper proposes three novel techniques for multivariate interpolation and regression that each have polynomial complexity with respect to number of instances (points) and number of attributes (dimension). Initial results suggest that these techniques are capable of effectively modeling multivariate phenomena while maintaining flexibility in different application domains.

<hr>
#### Convergence Rate Evaluation of Derivative Free Optimization Techniques
*September, 2016* [[pdf](http://people.cs.vt.edu/tchlux/papers/tchlux-2016-MOD.pdf)] [[link](https://link.springer.com/chapter/10.1007/978-3-319-51469-7_21)]

This paper presents a convergence rate comparison of five different derivative-free numerical optimization techniques across a set of 50 benchmark objective functions. Results suggest that Adaptive Memory Programming for constrained Global Optimization, and a variant of Simulated Annealing are two of the fastest-converging numerical optimization techniques in this set. Lastly, there is a mechanism for expanding the set of optimization algorithms provided.

<hr>
#### Applications of Supervised Learning Techniques on Undergraduate Admissions Data 
*May, 2016* [[pdf](http://people.cs.vt.edu/tchlux/papers/tchlux-2016-ACM_Computing_Frontiers.pdf)] [[link](https://dl.acm.org/citation.cfm?id=2911717)]

We discuss the use of supervised learning techniques in predicting admission decisions and enrollment based on historical applicant data. We show that a classifier trained and validated on previous years’ data can identify (1) applicants that the admissions office is likely to accept, and (2) those accepted students that are likely to enroll at the institution. Additionally, results from our feature selection experiments inform admissions offices of the significance of applicant features relative to acceptance and enrollment, thus aiding the office in future data collection and decision making.




<p height="100px"></p>

# Co-authored Publications

<hr>
#### MOANA: Modeling and Analyzing I/O Variability in Parallel System Experimental Design
*January, 2019* [[link](https://ieeexplore.ieee.org/document/8631172)]

Exponential increases in complexity and scale make variability a growing threat to sustaining HPC performance at exascale. We take the first step towards comprehensively studying linear and nonlinear approaches to modeling HPC I/O system variability in an effort to demonstrate that variability is often a predictable artifact of system design. Using over 8 months of data collection on 6 identical systems, we propose and validate a modeling and analysis approach (MOANA) that predicts HPC I/O variability for thousands of software and hardware configurations on highly parallel shared-memory systems. Our findings indicate nonlinear approaches to I/O variability prediction are an order of magnitude more accurate than linear regression techniques.

<hr>
#### Optimized Drag Reduction and Wake Dynamics Associated with Rotational Oscillations of a Circular Cylinder
*November, 2018* [[link](http://www.m-hikari.com/ces/ces2018/ces97-100-2018/89519.html)]

The drag reduction on a circular cylinder through rotational oscillations is globally maximized by coupling a CFD solver with a novel parallel global deterministic optimization algorithm. The simulations are performed at a Reynolds number of 150 and the amplitude and frequency of the rotational oscillations are respectively constrained to the ranges 0.1 ≤ Ω ≤ 1.0 and 0.1 ≤ fΩ ≤ 3.0. The novelty of this work lies in the use of a massively parallel derivative free optimization algorithm to find the globally (not locally, as is typically done) optimal values of the rotational amplitude and frequency for minimum drag.

<hr>
#### Prediction for Distributional Outcomes in the Management of High-Performance Computing Input/Output (I/O) Variability (Poster)
*July, 2018* [[link](https://ww2.amstat.org/meetings/jsm/2018/onlineprogram/AbstractDetails.cfm?abstractid=330148)]

One important research area in high-performance computing (HPC) is the management of performance variability, which is affected by complicated interactions of numerous factors, such as CPU frequency, the number of I/O threads, file size and record size. In this paper, we are interested in the I/O variability, which is measured by the I/O throughputs that varies from run to run. Given a system configuration, one way to describe the variability is to use the cumulative distribution function (cdf) for the throughputs. Prediction the cdf of throughputs for a new system configuration is often of interest, which, however, is a challenging task. To overcome this challenge, computer scientists conducted large-scale experiments and collected a mass amount of data for the distribution of variability under various system configurations. We develop a Gaussian process model to predict the cdf under a new configuration using the experimental data. We also impose a monotone constraint so that the predicted function is monotonically increasing, which is one desired property of the cdf. We evaluate the performance of the proposed method by using the experimental data.

<hr>
#### Computing the Umbrella Neighbourhood of a Vertex in the Delaunay Triangulation and a Single Voronoi Cell in Arbitrary Dimension
*April, 2018* [[link](https://ieeexplore.ieee.org/document/8479003)]

Delaunay triangulations and their geometric dual Voronoi diagrams are carefully studied topics in computational geometry and have numerous applications spanning fields such as physics, engineering, geographic information systems, and computer graphics. There are numerous efficient algorithms for computing both in two and three dimensional real space, but for higher dimensional space, the computational complexity grows exponentially. For many applications, it is only necessary to compute the star of simplices incident to (often called the umbrella neighbourhood of) a single vertex of the Delaunay triangulation, or equivalently, the Voronoi cell of a point. In practice, this may be a relatively small subset of the total Delaunay triangulation or Voronoi diagram. In this paper, an algorithm is proposed for computing the umbrella neighbourhood of a single vertex in the Delaunay triangulation.

<hr>
#### Predicting System Performance by Interpolation Using a High-Dimensional Delaunay Triangulation
*April, 2018* [[link](https://dl.acm.org/citation.cfm?id=3213071)]

When interpolating computing system performance data, there are many input parameters that must be considered. Therefore, the chosen multivariate interpolation model must be capable of scaling to many dimensions. The Delaunay triangulation is a foundational technique, commonly used to perform piecewise linear interpolation in computer graphics, physics, civil engineering, and geography applications. It has been shown to produce a simplex based mesh with numerous favorable properties for interpolation. This paper proposes a new algorithm for computing interpolated values from the Delaunay triangulation without computing the complete triangulation. The proposed algorithm is shown to scale to over 50 dimensions. Data is presented demonstrating interpolation using the Delaunay triangulation in a real world high performance computing system problem.

<hr>
#### A Polynomial Time Algorithm for Multivariate Interpolation in Arbitrary Dimension via the Delaunay Triangulation
*March, 2018* [[link](https://dl.acm.org/citation.cfm?doid=3190645.3190680)]

The Delaunay triangulation is a fundamental construct from computational geometry, which finds wide use as a model for multivariate piecewise linear interpolation in fields such as geographic information systems, civil engineering, physics, and computer graphics. The computational complexity for constructing the complete Delaunay triangulation grows exponentially in higher dimensions. Therefore, usage of the Delaunay triangulation as a model for interpolation in high-dimensional domains remains computationally infeasible by standard methods. In this paper, a polynomial time algorithm is presented for interpolating at a finite set of points in arbitrary dimension via the Delaunay triangulation.

<hr>
#### Teaching Variability in a Core Systems Course (Abstract Only)
*February, 2018* [[link](https://dl.acm.org/citation.cfm?id=3162275)]

This project emphasized teaching the effects (and prevalence) of computational performance variability to undergrads in a Computer Systems course. I (Thomas Lux) was involved in creating the visualization / analytics tool that the students in the course used to study the effects of variability in code that they wrote. While this is an abstract-only submission, it represents a nontrivial amount of time and effort spent creating effective & accessible visualizations that teach the concepts of variability.
